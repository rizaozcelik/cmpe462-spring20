{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(sample_size, n_features, rng, shift, weights, eps_coeff):\n",
    "    X = rng * np.random.rand(sample_size, n_features) + shift\n",
    "    X_intercept = np.hstack([X, np.ones((sample_size, 1))])\n",
    "    eps = eps_coeff * np.random.randn(sample_size, 1)\n",
    "    y = X_intercept @ weights + eps\n",
    "    \n",
    "    return X_intercept, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_regularized_regression(X, y, lambda_):\n",
    "    n_cols = X.shape[1]\n",
    "    return np.linalg.inv(X.T @ X + lambda_ * np.identity(n_cols)) @ X.T @ y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, w_star):\n",
    "    return X @ w_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y, y_hat):\n",
    "    return np.sqrt(np.mean(np.square(y - y_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_X_vs_y_with_solution(X, y, w0, w1, w0_star, w1_star, title):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    inputs = np.linspace(-(rng + shift), (rng + shift), 2)\n",
    "    plt.scatter(X[:, 0], y, label='Sampled Data', s=10)\n",
    "    plt.plot(inputs, w0 * inputs + w1, color='red', label='Actual Line')\n",
    "    plt.plot(inputs, w0_star * inputs + w1_star, color='purple', label='Predicted Line')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Feature')\n",
    "    plt.ylabel('Label')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    y_lim_top = plt.gca().get_ylim()[1]\n",
    "    plt.text(0, 0.9 * y_lim_top, f'w0: {w0}, w0_star:{round(w0_star, 3)}\\nw1: {w1}, w1_star:{round(w1_star, 4)}', bbox=dict(facecolor='white'),\n",
    "             verticalalignment='top')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size, n_features = 1000, 1\n",
    "rng, shift = 10, -5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[interact documentation](https://ipywidgets.readthedocs.io/en/latest/examples/Using%20Interact.html)\n",
    "[Available widget list](https://ipywidgets.readthedocs.io/en/latest/examples/Widget%20List.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed33920559a418cb3d7886366185586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, continuous_update=False, description='eps_coeff', step=0.5), Textâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact, FloatSlider, widgets\n",
    "\n",
    "def regression(eps_coeff, w0, w1):\n",
    "    w0, w1 = float(w0), float(w1)\n",
    "    weights = np.array([[w0], [w1]])\n",
    "    \n",
    "    X_train, y_train = create_dataset(sample_size, n_features, rng, shift, weights, eps_coeff)\n",
    "    X_test, y_test = create_dataset(sample_size // 4, n_features, rng, shift, weights, eps_coeff)\n",
    "\n",
    "    solution = solve_regularized_regression(X_train, y_train, 0)\n",
    "    w0_star, w1_star = solution[0, 0], solution[1, 0]\n",
    "    plot_X_vs_y_with_solution(X_train, y_train, w0, w1, w0_star, w1_star, 'Training Data')\n",
    "    \n",
    "    print(f'Test error: {root_mean_squared_error(y_test, predict(X_test, solution))}')\n",
    "    \n",
    "interact(regression,\n",
    "         eps_coeff=FloatSlider(min=0, max=100, step=.5, continuous_update=False),\n",
    "         w0=widgets.Text(value='5', placeholder='Enter a float', description='w0:', continuous_update=False),\n",
    "         w1=widgets.Text(value='10', placeholder='Enter a float', description='w1:', continuous_update=False));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Fun and Learning\n",
    " \n",
    "Go ahead and add more parameters to ipywidget and play with, such as regularization. Observe how the plot changes based on each parameter to build more intuitions on linear regression. Similarly, observe the things that do not change. For instance, how can linear regression so accurately predict the actual weights, even when the noise is quite high? Do you think it is always the case in real life data sets? (Hint: Definitely not :)) What makes the data set in this notebook this simple? How would you modify it to make it more realistic?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
